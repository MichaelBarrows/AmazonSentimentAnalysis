{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QAvvvloX3bC2"
   },
   "source": [
    "<h2>Algorithm Evaluation and Sentiment Predictions</h2>\n",
    "<p>This script evaluates 6 classification algorithms for their performance in relation to sentiment analysis of Amazon reviews.</p>\n",
    "<p>The classification algorithms for evaluation include:</p>\n",
    "<ul>\n",
    "    <li>Linear Support Vector Machine (SVM)</li>\n",
    "    <li>Feed Forward (Neural Network)</li>\n",
    "    <li>Na√Øve Bayes</li>\n",
    "    <li>Random Forest</li>\n",
    "    <li>Decision Tree</li>\n",
    "    <li>K-Nearest Neighbours (K-NN)</li>\n",
    "</ul>\n",
    "<p>The algorithms are evaluated using various values as modifiers, which in turn produce different results</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import Modules</h3>\n",
    "<p>This block imports the modules required pandas for handling CSV files and DataFrames; sklearn for the classification algorithms, metrics and converting each word to features. itemgetter is used to access a specific attribute while sorting lists.</p>\n",
    "<p>The <i>all_data</i> variable is a list, which will contain all of the outputs from the algorithm classifications, including: </p>\n",
    "<ul>\n",
    "    <li><b>[0]</b> - Algorithm Name</li>\n",
    "    <li><b>[1]</b> - Modifier Name</li>\n",
    "    <li><b>[2]</b> - Modifier Value</li>\n",
    "    <li><b>[3]</b> - List containing the predictions</li>\n",
    "    <li><b>[4]</b> - Precision</li>\n",
    "    <li><b>[5]</b> - Recall</li>\n",
    "    <li><b>[6]</b> - F-Score</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHjuqYxosvzb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from operator import itemgetter\n",
    "\n",
    "all_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>load_amazon_dataset (input_csv)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>input_csv</b> - [string] filename of the file containing the Amazon reviews</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>sentiment_scores</b> - [list] Actual class of the review</li>\n",
    "            <li><b>product_ids</b> - [list] Product ID the review relates to</li>\n",
    "            <li><b>text_reviews</b> - [list] Text of the review</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The <i>load_amazon_dataset()</i> method is used to extract the Amazon reviews from a file and convert them into a DataFrame</li>\n",
    "    <li>Once this is complete, three columns of the DataFrame are returned</li>\n",
    "   </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKxHBhTes1md"
   },
   "outputs": [],
   "source": [
    "def load_amazon_dataset(input_csv):\n",
    "    df = pd.read_csv(input_csv,\n",
    "                    delimiter='\\t',\n",
    "                    header=None)\n",
    "    sentiment_scores = df[0]\n",
    "    product_ids = df[1]\n",
    "    text_reviews = df[2]\n",
    "    return sentiment_scores, product_ids, text_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Obtaining the Amazon Reviews</h3>\n",
    "<h4>What does this block do?</h4>\n",
    "<ol>\n",
    "    <li>This block defines the file paths for the training and test Amazon reviews (<i>FILE_PATH_TO_TRAINING_REVIEWS</i> and <i>FILE_PATH_TO_TEST_REVIEWS</i> respectively)\n",
    "    <li>Calls the <i>load_amazon_dataset</i> twice, once for training reviews, once for test reviews. Results are stored in <i>&ast;_sentiment_scores</i>, <i>&ast;_product_ids</i> and <i>&ast;_text_reviews</i></li>\n",
    "    <li>Prints the length of the training and test text reviews</li>\n",
    "    <li>Prints the text and sentiment of the first review for training and test datasets</li>\n",
    "   </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "21s6In6qs2Tm",
    "outputId": "bd990935-6104-4703-b837-4b8a40a02f13"
   },
   "outputs": [],
   "source": [
    "FILE_PATH_TO_TRAINING_REVIEWS = 'Review Files/reviews_Apps_for_Android_5.training.txt'\n",
    "FILE_PATH_TO_TEST_REVIEWS = 'Review Files/reviews_Apps_for_Android_5.test.txt'\n",
    "\n",
    "training_sentiment_scores, training_product_ids, training_text_reviews = load_amazon_dataset(input_csv=FILE_PATH_TO_TRAINING_REVIEWS)\n",
    "test_sentiment_scores, test_product_ids, test_text_reviews = load_amazon_dataset(input_csv=FILE_PATH_TO_TEST_REVIEWS)\n",
    "print('Loaded ', len(training_text_reviews), ' training reviews')\n",
    "print('Loaded ', len(test_text_reviews), ' test reviews') \n",
    "print(training_text_reviews[0], '--sent. label--', training_sentiment_scores[0])\n",
    "print(test_text_reviews[0], '--sent. label--', test_sentiment_scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Converting Review Text to Bag of Words Features</h3>\n",
    "<h4>What does this block do?</h4>\n",
    "<ol>\n",
    "    <li>This block transforms the text of each training review to bag of words features for analysis</li>\n",
    "    <li>Transforms the test text review of each test review to bag of words using the training features</li>\n",
    "   </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "-HUH0IjEs4MJ",
    "outputId": "f9a8160d-76f1-4978-95d3-4f5719d4c137",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_vectorizer = CountVectorizer()\n",
    "training_vectorizer.fit(training_text_reviews)\n",
    "training_instances_bow = training_vectorizer.transform(training_text_reviews)\n",
    "\n",
    "test_vectorizer = CountVectorizer(vocabulary=training_vectorizer.get_feature_names())\n",
    "test_vectorizer.fit(test_text_reviews)\n",
    "test_instances_bow = test_vectorizer.fit_transform(test_text_reviews) \n",
    "print('Finished converting text reviews into bow')\n",
    "print('Generated', training_instances_bow.shape[1], ' bow features')\n",
    "print('Below are the first 1,000 bow features')\n",
    "print(training_vectorizer.get_feature_names()[0:999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>svm_linear_classification (c_value)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>c_value</b> -[integer] Modifier value</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>predicted_test_sentiment_scores</b> - [list] The predictions made by the classification algorithm</li>\n",
    "            <li><b>precision_recall_fscore_support()</b> - [list] Metrics of the classification algorithm's performance\n",
    "                <ul>\n",
    "                    <li>This method returns a list containing the precision, recall, f-score and support metrics using weighted averages</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The svm_linear_classification() method is used to implement the Linear Support Vector Machine classification algorithm with the C value modified to that provided by the parameter <i>c_value</i>.</li>\n",
    "    <li>The classifier variable is trained using the text and sentiment class of the training dataset</li>\n",
    "    <li>The trained classifier variable is then used to predict the sentiment class of each review in the test dataset</li>\n",
    "    <li>The predictions and metrics are then returned</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbqP4kXqtGzu"
   },
   "outputs": [],
   "source": [
    "def svm_linear_classification(c_value):\n",
    "    print(\"SVM Linear\", c_value)\n",
    "    classifier = LinearSVC(C=c_value)\n",
    "    classifier.fit(X=training_instances_bow, y=training_sentiment_scores)\n",
    "    print('Finished Training')\n",
    "    print('Predicting Test Instances')\n",
    "    predicted_test_sentiment_scores = classifier.predict(test_instances_bow)\n",
    "    return predicted_test_sentiment_scores, precision_recall_fscore_support(test_sentiment_scores, predicted_test_sentiment_scores, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>feed_forward_classification (layers, iterations)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>layers</b> - [list] A list, with each element in the list representing a layer, and the value of the element representing the number of nodes in the layer</li>\n",
    "            <li><b>iterations</b> - [integer] Used to limit the number of times the algorithm will attempt to correct the weightings of features</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>predicted_test_sentiment_scores</b> - [list] The predictions made by the classification algorithm</li>\n",
    "            <li><b>precision_recall_fscore_support()</b> - [list] Metrics of the classification algorithm's performance\n",
    "                <ul>\n",
    "                    <li>This method returns a list containing the precision, recall, f-score and support metrics using weighted averages</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The feed_forward_classification() method is used to implement the Feed Forward classification algorithm with the layers and iterations values modified to those provided by the parameters <i>layers</i> and <i>iterations</i>.</li>\n",
    "    <li>The classifier variable is trained using the text and sentiment class of the training dataset</li>\n",
    "    <li>The trained classifier variable is then used to predict the sentiment class of each review in the test dataset</li>\n",
    "    <li>The predictions and metrics are then returned</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wP__8gCGt2XZ"
   },
   "outputs": [],
   "source": [
    "def feed_forward_classification(layers, iterations):\n",
    "    print(\"Feed Forward\", layers, iterations)    \n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(layers),\n",
    "                           max_iter=iterations)\n",
    "    classifier.fit(training_instances_bow, training_sentiment_scores)\n",
    "    print('Finished Training')\n",
    "    print('Predicting Test Instances')\n",
    "    predicted_test_sentiment_scores = classifier.predict(test_instances_bow) \n",
    "    return predicted_test_sentiment_scores, precision_recall_fscore_support(test_sentiment_scores, predicted_test_sentiment_scores, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>naive_bayes_classification (alpha)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>alpha</b> - [integer] Modifier value</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>predicted_test_sentiment_scores</b> - [list] The predictions made by the classification algorithm</li>\n",
    "            <li><b>precision_recall_fscore_support()</b> - [list] Metrics of the classification algorithm's performance\n",
    "                <ul>\n",
    "                    <li>This method returns a list containing the precision, recall, f-score and support metrics using weighted averages</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The naive_bayes_classification() method is used to implement the Na√Øve Bayes classification algorithm with the alpha value modified to that provided by the <i>alpha</i> parameter.</li>\n",
    "    <li>The classifier variable is trained using the text and sentiment class of the training dataset</li>\n",
    "    <li>The trained classifier variable is then used to predict the sentiment class of each review in the test dataset</li>\n",
    "    <li>The predictions and metrics are then returned</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPNFoQ6_t2Tn"
   },
   "outputs": [],
   "source": [
    "def naive_bayes_classification(alpha):\n",
    "    print(\"Naive Bayes\", alpha)\n",
    "    classifier = MultinomialNB(alpha=alpha)\n",
    "    classifier.fit(training_instances_bow, training_sentiment_scores)\n",
    "    print('Finished Training')\n",
    "    print('Predicting Test Instances')\n",
    "    predicted_test_sentiment_scores = classifier.predict(test_instances_bow)\n",
    "    return predicted_test_sentiment_scores, precision_recall_fscore_support(test_sentiment_scores, predicted_test_sentiment_scores, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>random_forest_classification (trees, features)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>trees</b> - [integer] The number of decision trees to be used in the random forest</li>\n",
    "            <li><b>features</b> - [integer] The number of features to be taken into consideration by the algorithm</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>predicted_test_sentiment_scores</b> - [list] The predictions made by the classification algorithm</li>\n",
    "            <li><b>precision_recall_fscore_support()</b> - [list] Metrics of the classification algorithm's performance\n",
    "                <ul>\n",
    "                    <li>This method returns a list containing the precision, recall, f-score and support metrics using weighted averages</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The random_forest_classification() method is used to implement the Random Forest classification algorithm with the trees and features values modified to those provided by the <i>trees</i> and <i>features</i> parameters.</li>\n",
    "    <li>The classifier variable is trained using the text and sentiment class of the training dataset</li>\n",
    "    <li>The trained classifier variable is then used to predict the sentiment class of each review in the test dataset</li>\n",
    "    <li>The predictions and metrics are then returned</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZcNO2UG3bEd"
   },
   "outputs": [],
   "source": [
    "def random_forest_classification(trees, features):\n",
    "    print(\"Random Forest\", trees, features)\n",
    "    classifier = RandomForestClassifier(n_estimators=trees,\n",
    "                                    max_features=features,\n",
    "                                    n_jobs=100)\n",
    "    classifier.fit(training_instances_bow, training_sentiment_scores)\n",
    "    print('Finished Training')\n",
    "    print('Predicting Test Instances')\n",
    "    predicted_test_sentiment_scores = classifier.predict(test_instances_bow)\n",
    "    return predicted_test_sentiment_scores, precision_recall_fscore_support(test_sentiment_scores, predicted_test_sentiment_scores, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>decision_tree_classification ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>predicted_test_sentiment_scores</b> - [list] The predictions made by the classification algorithm</li>\n",
    "            <li><b>precision_recall_fscore_support()</b> - [list] Metrics of the classification algorithm's performance\n",
    "                <ul>\n",
    "                    <li>This method returns a list containing the precision, recall, f-score and support metrics using weighted averages</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The decision_tree_classification() method is used to implement the Decision Tree classification algorithm with no modifiers <b>[as this algorithm doesnt have these???]</b></li>\n",
    "    <li>The classifier variable is trained using the text and sentiment class of the training dataset</li>\n",
    "    <li>The trained classifier variable is then used to predict the sentiment class of each review in the test dataset</li>\n",
    "    <li>The predictions and metrics are then returned</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nf657-v-3bEn"
   },
   "outputs": [],
   "source": [
    "def decision_tree_classification():\n",
    "    print(\"Decision Tree\")\n",
    "    classifier = tree.DecisionTreeClassifier()\n",
    "    classifier.fit(training_instances_bow, training_sentiment_scores)\n",
    "    print('Finished Training')\n",
    "    print('Predicting Test Instances')\n",
    "    predicted_test_sentiment_scores = classifier.predict(test_instances_bow)\n",
    "    return predicted_test_sentiment_scores, precision_recall_fscore_support(test_sentiment_scores, predicted_test_sentiment_scores, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>k_nn_classification (neighbours)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>neighbours</b> - [integer] the number of neighbours to be used for evaluation</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>predicted_test_sentiment_scores</b> - [list] The predictions made by the classification algorithm</li>\n",
    "            <li><b>precision_recall_fscore_support()</b> - [list] Metrics of the classification algorithm's performance\n",
    "                <ul>\n",
    "                    <li>This method returns a list containing the precision, recall, f-score and support metrics using weighted averages</li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The k_nn_classification() method is used to implement the K-Nearest Neighbours classification algorithm with the neighbours value modified to that provided by the <i>neighbours</i> parameter.</li>\n",
    "    <li>The classifier variable is trained using the text and sentiment class of the training dataset</li>\n",
    "    <li>The trained classifier variable is then used to predict the sentiment class of each review in the test dataset</li>\n",
    "    <li>The predictions and metrics are then returned</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6ZBzUr33bE2"
   },
   "outputs": [],
   "source": [
    "def k_nn_classification(neighbours):\n",
    "    print(\"K-NN\", neighbours)\n",
    "    classifier = KNeighborsClassifier(n_neighbors=neighbours)\n",
    "    classifier.fit(training_instances_bow, training_sentiment_scores)\n",
    "    print('Finished Training')\n",
    "    print('Predicting Test Instances')\n",
    "    predicted_test_sentiment_scores = classifier.predict(test_instances_bow) \n",
    "    return predicted_test_sentiment_scores, precision_recall_fscore_support(test_sentiment_scores, predicted_test_sentiment_scores, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>evaluate_svm_linear ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The evaluate_linear_svm() method iterates over the list of (sorted) modifier values (<i>c_values</i>) and calls the <i>svm_linear_classification()</i> method with the current modifier value which runs the algorithm with the modified value</li>\n",
    "    <li>The data returned from the <i>svm_linear_classification</i> method is stored in the <i>predictions</i> and <i>metrics</i> variables</li>\n",
    "    <li>The data contained in the <i>predictions</i> and <i>metrics</i> variables is then stored in the <i>all_data</i> global variable (with the attributes in the order shown where the global <i>all_data</i> variable is declared</li>\n",
    "    <li>The data stored in the <i>all_data</i> variable is also printed so the user can see the performance of algorithm with this modifier</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9IJyc6X3bF1"
   },
   "outputs": [],
   "source": [
    "def evaluate_svm_linear():\n",
    "    global all_data\n",
    "    c_values = [0.05, 0.02, 0.001, 0.01, 0.3, 0.2, 0.1, 2, 10, 0.0001, 1, 3, 0.03, 5]\n",
    "    c_values.sort()\n",
    "    for c_value in c_values:\n",
    "        predictions, metrics = svm_linear_classification(c_value)\n",
    "        all_data.append(['SVM Linear', 'C Value', c_value, predictions, round(metrics[0], 4), round(metrics[1], 4), round(metrics[2], 4)])\n",
    "        print(all_data[-1][0], \"C_Value\", all_data[-1][2], \"Precision\", all_data[-1][4], \"Recall\", all_data[-1][5], \"F-Score\", all_data[-1][6], \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>evaluate_feed_forward ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The evaluate_feed_forward() method iterates over the list of (sorted) modifier values (<i>values</i>) and calls the <i>feed_forward_classification()</i> method with the current modifier values (<i>layers</i> and <i>iterations</i>) which runs the algorithm with the modified values</li>\n",
    "    <li>The data returned from the <i>feed_forward_classification</i> method is stored in the <i>predictions</i> and <i>metrics</i> variables</li>\n",
    "    <li>The data contained in the <i>predictions</i> and <i>metrics</i> variables is then stored in the <i>all_data</i> global variable (with the attributes in the order shown where the global <i>all_data</i> variable is declared</li>\n",
    "    <li>The data stored in the <i>all_data</i> variable is also printed so the user can see the performance of algorithm with this modifier</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feed_forward():\n",
    "    global all_data\n",
    "    values = [[[100], 150], [[100], 200], [[100, 50], 200], [[100, 50], 150], \n",
    "          [[100, 75, 50], 100], [[100,75,50], 125], [[100,75,50], 150], \n",
    "          [[15], 100], [[200, 100], 125], [[200, 100], 150], [[25], 150], \n",
    "          [[300], 100], [[35], 150], [[35, 20], 100], [[35, 25], 150], \n",
    "          [[65, 20], 100], [[65, 30], 200], [[65, 30, 10], 150], [[75, 55], 100], \n",
    "          [[75, 55], 125], [[75, 55], 200]]\n",
    "    values.sort()\n",
    "    for layers, iterations in values:\n",
    "        predictions, metrics = feed_forward_classification(layers, iterations)\n",
    "        all_data.append(['Feed Forward', 'Layers; Iterations', str(layers) + \";\" + str(iterations), predictions, round(metrics[0], 4), round(metrics[1], 4), round(metrics[2], 4)])\n",
    "        print(all_data[-1][0], \"[Layers]:Iterations\", all_data[-1][2], \"Precision\", all_data[-1][4], \"Recall\", all_data[-1][5], \"F-Score\", all_data[-1][6], \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>evaluate_naive_bayes ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The evaluate_naive_bayes() method iterates over the list of (sorted) modifier values (<i>values</i>) and calls the <i>naive_bayes_classification()</i> method with the current modifier value which runs the algorithm with the modified value</li>\n",
    "    <li>The data returned from the <i>naive_bayes_classification</i> method is stored in the <i>predictions</i> and <i>metrics</i> variables</li>\n",
    "    <li>The data contained in the <i>predictions</i> and <i>metrics</i> variables is then stored in the <i>all_data</i> global variable (with the attributes in the order shown where the global <i>all_data</i> variable is declared</li>\n",
    "    <li>The data stored in the <i>all_data</i> variable is also printed so the user can see the performance of algorithm with this modifier</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_naive_bayes():\n",
    "    global all_data\n",
    "    values = [0.001, 0.01, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0, 2.0, 3.0, 5.0, 10.0]\n",
    "    values.sort()\n",
    "    for value in values:\n",
    "        predictions, metrics = naive_bayes_classification(value)\n",
    "        all_data.append(['Naive Bayes', 'Alpha Value', value, predictions, round(metrics[0], 4), round(metrics[1], 4), round(metrics[2], 4)])\n",
    "        print(all_data[-1][0], \"Alpha\", all_data[-1][2], \"Precision\", all_data[-1][4], \"Recall\", all_data[-1][5], \"F-Score\", all_data[-1][6], \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>evaluate_random_forest ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The evaluate_random_forest() method iterates over the list of modifier values (<i>values</i>) and calls the <i>random_forest_classification()</i> method with the current modifier values (<i>trees</i> and <i>features</i>) which runs the algorithm with the modified values</li>\n",
    "    <li>The data returned from the <i>random_forest_classification</i> method is stored in the <i>predictions</i> and <i>metrics</i> variables</li>\n",
    "    <li>The data contained in the <i>predictions</i> and <i>metrics</i> variables is then stored in the <i>all_data</i> global variable (with the attributes in the order shown where the global <i>all_data</i> variable is declared</li>\n",
    "    <li>The data stored in the <i>all_data</i> variable is also printed so the user can see the performance of algorithm with this modifier</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_forest():\n",
    "    global all_data\n",
    "    values = [[50, 1000], [50, 5000], [50, 10000],\n",
    "               [100, 3], [100, 100], [100, 200], [100, 300],\n",
    "               [150, 50],\n",
    "               [200, 50], [200, 100], [200, 300],\n",
    "               [300, 10], [300, 20], [300, 50], [300, 100], [300, 500], [300, 1000], [300, 5000]]\n",
    "    for trees, features in values:\n",
    "        predictions, metrics = random_forest_classification(trees, features)\n",
    "        all_data.append(['Random Forest', 'Trees; Features', str(trees) + \";\" + str(features), predictions, round(metrics[0], 4), round(metrics[1], 4), round(metrics[2], 4)])\n",
    "        print(all_data[-1][0], \"trees;features\", all_data[-1][2], \"Precision\", all_data[-1][4], \"Recall\", all_data[-1][5], \"F-Score\", all_data[-1][6], \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>evaluate_decision_tree ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The evaluate_decision_tree() method calls the <i>decision_tree_classification()</i> method which runs the algorithm.</li>\n",
    "    <li>The data returned from the <i>decision_tree_classification</i> method is stored in the <i>predictions</i> and <i>metrics</i> variables</li>\n",
    "    <li>The data contained in the <i>predictions</i> and <i>metrics</i> variables is then stored in the <i>all_data</i> global variable (with the attributes in the order shown where the global <i>all_data</i> variable is declared</li>\n",
    "    <li>The data stored in the <i>all_data</i> variable is also printed so the user can see the performance of the decision tree algorithm</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_decision_tree():\n",
    "    global all_data\n",
    "    predictions, metrics = decision_tree_classification()\n",
    "    all_data.append(['Decision Tree', '', '' , predictions, round(metrics[0], 4), round(metrics[1], 4), round(metrics[2], 4)])\n",
    "    print(all_data[-1][0], \"\", all_data[-1][2], \"Precision\", all_data[-1][4], \"Recall\", all_data[-1][5], \"F-Score\", all_data[-1][6], \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>evaluate_k_nn ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The evaluate_k_nn() method iterates over the list of (sorted) modifier values (<i>values</i>) and calls the <i>k_nn_classification()</i> method with the current modifier value which runs the algorithm with the modified value</li>\n",
    "    <li>The data returned from the <i>k_nn_classification()</i> method is stored in the <i>predictions</i> and <i>metrics</i> variables</li>\n",
    "    <li>The data contained in the <i>predictions</i> and <i>metrics</i> variables is then stored in the <i>all_data</i> global variable (with the attributes in the order shown where the global <i>all_data</i> variable is declared</li>\n",
    "    <li>The data stored in the <i>all_data</i> variable is also printed so the user can see the performance of algorithm with this modifier</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_k_nn():\n",
    "    global all_data\n",
    "    values = [1, 3, 5, 7, 9, 11]\n",
    "    values.sort()\n",
    "    for value in values:\n",
    "        predictions, metrics = k_nn_classification(value)\n",
    "        all_data.append(['K-NN', 'Neighbours', value, predictions, round(metrics[0], 4), round(metrics[1], 4), round(metrics[2], 4)])\n",
    "        print(all_data[-1][0], all_data[-1][1], all_data[-1][2], \"Precision\", all_data[-1][4], \"Recall\", all_data[-1][5], \"F-Score\", all_data[-1][6], \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>pull_individual_algorithm_data (algorithm)</h3>\n",
    "\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>algorithm</b> - [string] The name of the algorithm that data is being retrieved for</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>algorithm_data</b> - [list] List containing the data for the selected algorithm</li>\n",
    "            <li><b>algorithm_name</b> - [string] The name of the algorithm</li>\n",
    "            <li><b>algorithm_modifier_name</b> - [string] The name of the algorithm modifier</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The pull_individual_algorithm_data() method iterates over <i>all_data</i> list and checks if the first attribute (algorithm name) matches the algorithm name provided as the parameter (<i>algorithm</i>)</li>\n",
    "    <li>If the algorithm names match, the following data is extracted from the global <i>all_data</i> list:\n",
    "        <ul>\n",
    "            <li><b>[2]</b> - Modifier Value</li>\n",
    "            <li><b>[4]</b> - Precision</li>\n",
    "            <li><b>[5]</b> - Recall</li>\n",
    "            <li><b>[6]</b> - F-Score</li>\n",
    "            <li><b>[3]</b> - List containing the predictions</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The extracted data is then added to the <i>algorithm_data</i></li>\n",
    "    <li>The <i>algorithm_name</i> and <i>algorithm_modifier_name</i> variables are then set with the name (contained in [0]) and the modifier name (contained in [1])</li>\n",
    "    <li>Once the for loop completes processing the <i>all_data</i> global variable, the <i>algorithm_data</i>, <i>algorithm_name</i> and <i>algorithm_modifier_name</i> variables are returned</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1489
    },
    "colab_type": "code",
    "id": "DUHVD2lJ3bGU",
    "outputId": "1d1af42a-5cfa-449e-9210-4f64fbb6bc8a"
   },
   "outputs": [],
   "source": [
    "def pull_individual_algorithm_data(algorithm):\n",
    "    global all_data\n",
    "    algorithm_data = []\n",
    "    algorithm_name, algorithm_modifier_name = '', ''\n",
    "    for data in all_data:\n",
    "        if data[0] == algorithm:\n",
    "            algorithm_data.append([data[2], data[4], data[5], data[6], data[3]])\n",
    "            algorithm_name = data[0]\n",
    "            algorithm_modifier_name = data[1]\n",
    "    return algorithm_data, algorithm_name, algorithm_modifier_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>get_data_from_single_column (data, column)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>data</b> - [list] The list of data for a single algorithm</li>\n",
    "            <li><b>column</b> - [integer] An integer identifying a column index in the <i>data</i> list</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>list_to_return</b> - [list] A list containing only the values in the specified index of the <i>data</i> list</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The get_data_from_single_column() method iterates over <i>data</i> paramater (list) and the data contained in the row at the <i>column</i> index is added to the <i>list_to_return</i> list</li>\n",
    "    <li>The <i>list_to_return</i> variable is then returned\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_single_column(data, column):\n",
    "    list_to_return = []\n",
    "    for row in data:\n",
    "        list_to_return.append(row[column])\n",
    "    return list_to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>create_dataframe (data)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>data</b> - [list] The list of data for a single algorithm</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>dataframe</b> - [dataframe] A dataframe containing the modifier value, precision, recall and f-score from <i>data</i></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The create_dataframe() method creates a dictionary (<i>data_dict</i>) containing the following columns from the <i>data</i> parameter:\n",
    "        <ul>\n",
    "            <li><b>[1]</b> - precision</li>\n",
    "            <li><b>[2]</b> - recall</li>\n",
    "            <li><b>[3]</b> - f-score</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>The dataframe is creates using the <i>data_dict</i> dictionary, with an index of the algorithm modifier value ([0])</li>\n",
    "    <li>The <i>dataframe</i> variable is then returned\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(data):\n",
    "    data_dict = {'Precision': get_data_from_single_column(data, 1), 'Recall': get_data_from_single_column(data, 2), 'F-Score': get_data_from_single_column(data, 3)}\n",
    "    dataframe = pd.DataFrame(data=data_dict, index=get_data_from_single_column(data, 0))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>sort_predictions (data)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>data</b> - [list] The list of data for a single algorithm</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>data</b> - [list] The sorted list of data for a single algorithm</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The sort_predictions() method sorts the <i>data</i> list by the f-score (<i>data[3]</i>) (high-low)</li>\n",
    "    <li>The sorted list is then returned</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_predictions(data):\n",
    "    data = sorted(data, key=itemgetter(3), reverse=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>store_best_predictions (data, name, modifier)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>data</b> - [list] The list of data for a single algorithm</li>\n",
    "            <li><b>name</b> - [string] The name of the algorithm</li>\n",
    "            <li><b>modifier</b> - [string] The name of the algorithm modifier</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>.CSV file</b> - [file] file containing the product ID's and predicted sentiment classes</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>A <i>filename</i> is created from the algorithm name, modifier name, and modifier value</li>\n",
    "    <li>The method then creates the file and iterates over the <i>data</i> list, outputting the product_id and the predictions which are stored in the file</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_best_predictions(data, name, modifier):\n",
    "    filename = 'Predictions/' + name + ' - ' + modifier + ' ' + str(data[0][0]) + ' - Predictions.csv'\n",
    "    header = \"product_id,predicted_sentiment_score\\n\"\n",
    "    print('Storing Predictions')\n",
    "    with open(file=filename, mode='w') as file_writer:\n",
    "        file_writer.write(header)\n",
    "        for idx in range(0, len(data[0][-1])):\n",
    "            file_writer.write(str(test_product_ids[idx]) + \",\" + str(data[0][-1][idx]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>create_graph_and_store_predictions (algorithm)</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>algorithm</b> - [string] The name of the algorithm</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>.PNG file</b> - [file] image file containing graph</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The create_graph_and_store_predictions() method is used to store the algorithms best predictions and to create a graph representing the performance results</li>\n",
    "    <li>The method gets all the data for the specific algorithm using the <i>pull_individula_algorithm_data()</i> method</li>\n",
    "    <li>A dataframe is created from the algorithm specific data using the <i>create_dataframe()</i> method</li>\n",
    "    <li>A bar graph is then created with customised colours and size</li>\n",
    "    <li>The Y axis boundaries for the graphs are then set (the range is consistent regardless of algorithm as all had a minimum f-score of 0.60 and a maximum of 0.80)</li>\n",
    "    <li>The X axis label (the modifier) is then set</li>\n",
    "    <li>The graph is then stored and the predictions are sorted and stored using the <i>sort_and_store_best_predictions()</i> method</li>\n",
    "    <li>Finally, the predictions for all of the entries in the all_data list are replaced with an empty string (to ensure RAM is not filled up)\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_and_store_predictions(algorithm):\n",
    "    data, name, modifier = pull_individual_algorithm_data(algorithm)\n",
    "    data = sorted(data, key=itemgetter(3))\n",
    "    dataframe = create_dataframe(data)\n",
    "    print(algorithm)\n",
    "    print('Creating Graph')\n",
    "    title = algorithm + ' Performance'\n",
    "    graph = dataframe.plot.bar(color=['#C44E52', '#55A868', '#4C72B0'], figsize=(15,11), title=title)\n",
    "    graph.set_ylim(bottom=0.60, top=0.825)\n",
    "    graph.set_xlabel(modifier)\n",
    "    graph = graph.get_figure()\n",
    "    graph.savefig('Graphs/' + algorithm.replace(\" \", \"_\") + '.png')\n",
    "    store_best_predictions(sort_predictions(data), name, modifier)\n",
    "    print(\"Complete \\n\")\n",
    "    global all_data\n",
    "    for row in range(len(all_data)):\n",
    "        all_data[row][3] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation, Performance Graphs and Storing Predictions</h3>\n",
    "<p>This section calls the methods for running the evaluation algorithms, generating graphs and storing the best predictions</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2332
    },
    "colab_type": "code",
    "id": "UMDvaM0N3bGE",
    "outputId": "5b2b8aaa-1528-4ad0-b422-47de8570723d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_svm_linear()\n",
    "create_graph_and_store_predictions(\"SVM Linear\")\n",
    "evaluate_feed_forward()\n",
    "create_graph_and_store_predictions(\"Feed Forward\")\n",
    "evaluate_naive_bayes()\n",
    "create_graph_and_store_predictions(\"Naive Bayes\")\n",
    "evaluate_random_forest()\n",
    "create_graph_and_store_predictions(\"Random Forest\")\n",
    "evaluate_decision_tree()\n",
    "create_graph_and_store_predictions(\"Decision Tree\")\n",
    "evaluate_k_nn()\n",
    "create_graph_and_store_predictions(\"K-NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>analysis_output ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The analysis_output() method sorts the results contained in the <i>all_data</i> global variable by f-score from highest to lowest</li>\n",
    "    <li>The performance details for the best performing algorithm are printed for the user to see</li>\n",
    "    <li>A DataFrame is created containing the performance results for all of the performance data (algorithm, modifier, modifier value, precision, recall and f-score)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xtdin4ty3bHL"
   },
   "outputs": [],
   "source": [
    "def analysis_output():\n",
    "    global all_data\n",
    "    all_data = sorted(all_data, key=itemgetter(6), reverse=True)\n",
    "    \n",
    "    print(\"The best performing algorithm was\", all_data[0][0], \"with a\", all_data[0][1], \"of\", all_data[0][2])\n",
    "    print(\"This algorithm had the following results:\\n\")\n",
    "    print(\"Precision\", all_data[0][4])\n",
    "    print(\"Recall\", all_data[0][5])\n",
    "    print(\"F-Score\", all_data[0][6], \"\\n\")\n",
    "    \n",
    "    print(\"A table of all results is shown below\")\n",
    "    data_df = {'Algorithm': get_data_from_single_column(all_data, 0),\n",
    "               'Modifier': get_data_from_single_column(all_data, 1),\n",
    "               'Modifier Value': get_data_from_single_column(all_data, 2),\n",
    "               'Precision': get_data_from_single_column(all_data, 4),\n",
    "               'Recall': get_data_from_single_column(all_data, 5),\n",
    "               'F-Score': get_data_from_single_column(all_data, 6)}\n",
    "    all_data_df = pd.DataFrame(data=data_df, index=range(1,len(all_data)+1))\n",
    "    print(all_data_df, \"\\n\\n\")\n",
    "    print(\"The predictions for the best performing instance of each algorithm have been stored in CSV files in the \\'Predictions\\' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>report_output ()</h3>\n",
    "<ul>\n",
    "    <li><u>Inputs</u>\n",
    "        <ul>\n",
    "            <li><b>NONE</b></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><u>Outputs</u>\n",
    "        <ul>\n",
    "            <li><b>.TXT file</b> - [file] containing the performance data in the format for a LaTeX table</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "    \n",
    "<h4>What does this method do?</h4>\n",
    "<ol>\n",
    "    <li>The report_output() method creates a text file <i>Algorithm Performance Results (LaTeX Table Format).txt</i> to store the data</li>\n",
    "    <li>Writes the table header to the file</li>\n",
    "    <li>Iterates over the data contained in the <i>all_data</i> global variable which is already sorted and writes it to the file</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_output():\n",
    "    global all_data\n",
    "    with open(file='Algorithm Performance Results (LaTeX Table Format).txt', mode='w') as file_writer:\n",
    "        file_writer.write(\"\\\\begin{table}[H]\\n\")\n",
    "        file_writer.write(\"  \\\\caption{All Algorithm Results (Ordered by F-Score [Largest to Smallest])}\\n\")\n",
    "        file_writer.write(\"  \\\\label{tab:all-algorithm-results-1}\\n\")\n",
    "        file_writer.write(\"  \\\\centering\\n\")\n",
    "        file_writer.write(\"  \\\\begin{tabular}{c|c|c|c|c|c}\\n\")\n",
    "        file_writer.write(\"    \\\\toprule\\n\")\n",
    "        \n",
    "        file_writer.write(\"    Algorithm & Modifier & Modifier Value & Precision & Recall & F-Score \\\\\\\\ \\n\")\n",
    "        file_writer.write(\"    \\\\midrule \\n\")\n",
    "        for data in all_data:\n",
    "            file_writer.write(\"    \" + str(data[0]) + \" & \" + str(data[1]) + \" & \" + str(data[2]) + \" & \" + str(data[4]) + \" & \" + str(data[5]) + \" & \" + str(data[6]) + \" \\\\\\\\\\n\")\n",
    "        file_writer.write(\"    \\\\bottomrule\\n\")\n",
    "        file_writer.write(\"  \\\\end{tabular}\\n\")\n",
    "        file_writer.write(\"\\\\end{table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Performance Results and Storing Results for Report</h3>\n",
    "<p>This section calls the methods for presenting the performance results and storing the performance data in a LaTeX table</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_output()\n",
    "report_output()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Data Predictions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
